{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dynamically add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from db_config import db\n",
    "from db_config.db_tables import Matches, Offer\n",
    "from sklearn.model_selection import train_test_split, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for matchings and matching scores\n",
    "matchings = []\n",
    "matchings_entries = []\n",
    "matching_score = 0\n",
    "\n",
    "#define matching score function\n",
    "# Calculate matching score based on euclidean distance\n",
    "def calculate_matching_score(df, user1, user2):\n",
    "    user1_preferences = df[df['user_id'] == user1].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    user2_preferences = df[df['user_id'] == user2].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    return euclidean(user1_preferences, user2_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define matching score function\n",
    "# Calculate matching score based on euclidean distance\n",
    "def calculate_matching_score(df, user1, user2):\n",
    "    user1_preferences = df[df['user_id'] == user1].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    user2_preferences = df[df['user_id'] == user2].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    return euclidean(user1_preferences, user2_preferences)\n",
    "\n",
    "#define clustering function\n",
    "def clustering_function(session_id):\n",
    "    df = pd.read_sql('SELECT * FROM preferences', db.engine)\n",
    "    df_later = df.copy()\n",
    "    print('1:', df[df['user_id'] == session_id])\n",
    "    #replace NaNs with True to avoid errors\n",
    "    df = df.fillna(True)\n",
    "\n",
    "    print('2:', df[df['user_id'] == session_id])\n",
    "\n",
    "    #  Define features and hot-encode categorical variables\n",
    "    X = pd.get_dummies(df[[\"pets\", \"sex\", \"age\", \"smoking\"]])\n",
    "    #make sure true and false are replaced with 0 and 1\n",
    "    X = np.where(X == True, 1, X)\n",
    "    X = np.where(X == False, 0, X)\n",
    "\n",
    "    # Split the data into training and testing sets (5 fold cross validation)\n",
    "    X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Standardize features (preprocessing to improve model performance)\n",
    "    scaler = StandardScaler() \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    print('3:', df[df['user_id'] == session_id])\n",
    "\n",
    "    #define our clusters\n",
    "    #define cluster list, start from 2 so that silhouette score can be calculated\n",
    "    cluster_amount = list(range(10, 100))\n",
    "    best_score = -1\n",
    "    best_cluster = None\n",
    "    for i in cluster_amount:\n",
    "        kmeans = KMeans(n_clusters=i)\n",
    "        #fit the model \n",
    "        df['cluster'] = kmeans.fit_predict(X_train)\n",
    "\n",
    "        #Evaluate performance using the silhouette score and find best performing cluster amount\n",
    "        silhouette_avg = silhouette_score(X_train, df['cluster'])\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_cluster = i\n",
    "\n",
    "    print('4:', df[df['user_id'] == session_id])\n",
    "\n",
    "    # print(f'Best Silhouette Score is: {best_score} for {best_cluster} clusters')\n",
    "\n",
    "    #fit the model for best amount of clusters\n",
    "    kmeans = KMeans(n_clusters=best_cluster)\n",
    "\n",
    "    #add the cluster to the dataframe\n",
    "    df['cluster'] = kmeans.fit_predict(X_train)\n",
    "\n",
    "    print('5:', df[df['user_id'] == session_id])\n",
    "\n",
    "    # Group customers by cluster\n",
    "    clusters = df.groupby('cluster')['user_id'].apply(list).to_dict()\n",
    "\n",
    "    print('6:', clusters)\n",
    "\n",
    "    # Add the matching customers to the matchings list\n",
    "    for cluster, customers in clusters.items():\n",
    "        for i in range(len(customers)):\n",
    "            for j in range(len(customers)):\n",
    "                if i != j:  # Avoid self-matching\n",
    "                    matchings.append((customers[i], customers[j]))\n",
    "\n",
    "    # Convert matches to a DataFrame for better clarity\n",
    "    matches_df = pd.DataFrame(matchings, columns=['user_id', 'offer_id'])\n",
    "\n",
    "    print('7:', matches_df[matches_df['user_id'] == session_id])\n",
    "\n",
    "    # Add matching score to matches_df\n",
    "    matches_df['matching_score'] = matches_df.apply(lambda row: calculate_matching_score(df_later, row['user_id'], row['offer_id']), axis=1)\n",
    "\n",
    "    print('8:', matches_df[matches_df['user_id'] == session_id])\n",
    "\n",
    "    # Sort matches by matching score in ascending order (lower distance means better match)\n",
    "    matches_df = matches_df.sort_values(by='matching_score')\n",
    "    # Normalize matching scores to a range of 0-100\n",
    "    min_score = matches_df['matching_score'].min()\n",
    "    max_score = matches_df['matching_score'].max()\n",
    "\n",
    "    print('9:', matches_df[matches_df['user_id'] == session_id])\n",
    "\n",
    "    matches_df['normalized_matching_score'] = 100 * (1 - (matches_df['matching_score'] - min_score) / (max_score - min_score))\n",
    "\n",
    "    print('10:', matches_df[matches_df['user_id'] == session_id])\n",
    "\n",
    "    # Print the DataFrame with normalized scores to check if it works\n",
    "    print(matches_df)\n",
    "    print(session_id)\n",
    "\n",
    "    # Add matches to the database \n",
    "    this_df = matches_df[matches_df['user_id'] == session_id]\n",
    "\n",
    "    print(this_df)\n",
    "\n",
    "    # delete old matches\n",
    "    Matches.query.filter_by(user_id=session_id).delete()\n",
    "    db.session.commit()\n",
    "    \n",
    "    for index, row in this_df.iterrows():\n",
    "        offer = Offer.query.filter_by(user_id=int(row['offer_id'])).first()\n",
    "        # append to database\n",
    "        new_match = Matches(\n",
    "            user_id=session_id,\n",
    "            offer_id=int(offer.id),\n",
    "            score=float(row['normalized_matching_score'])\n",
    "        )\n",
    "        db.session.add(new_match)\n",
    "    db.session.commit()\n",
    "\n",
    "    return matchings_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell compares the matching scores for train and test data to improve performance and avoid overfitting\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM preferences', db.engine)\n",
    "df_later = df.copy()\n",
    "print('1:', df[df['user_id'] == session_id])\n",
    "#replace NaNs with True to avoid errors\n",
    "df = df.fillna(True)\n",
    "\n",
    "print('2:', df[df['user_id'] == session_id])\n",
    "\n",
    "#  Define features and hot-encode categorical variables\n",
    "X = pd.get_dummies(df[[\"pets\", \"sex\", \"age\", \"smoking\"]])\n",
    "#make sure true and false are replaced with 0 and 1\n",
    "X = np.where(X == True, 1, X)\n",
    "X = np.where(X == False, 0, X)\n",
    "\n",
    "# Split the data into training and testing sets (5 fold cross validation)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "#Standardize features (preprocessing to improve model performance)\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('3:', df[df['user_id'] == session_id])\n",
    "\n",
    "#define our clusters\n",
    "#define cluster list, start from 2 so that silhouette score can be calculated\n",
    "cluster_amount = list(range(10, 100))\n",
    "best_score = -1\n",
    "best_cluster = None\n",
    "for i in cluster_amount:\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    #fit the model \n",
    "    df['cluster'] = kmeans.fit_predict(X_train)\n",
    "\n",
    "    #Evaluate performance using the silhouette score and find best performing cluster amount\n",
    "    silhouette_avg = silhouette_score(X_train, df['cluster'])\n",
    "    if silhouette_avg > best_score:\n",
    "        best_score = silhouette_avg\n",
    "        best_cluster = i\n",
    "\n",
    "print('4:', df[df['user_id'] == session_id])\n",
    "\n",
    "# print(f'Best Silhouette Score is: {best_score} for {best_cluster} clusters')\n",
    "\n",
    "#fit the model for best amount of clusters\n",
    "kmeans = KMeans(n_clusters=best_cluster)\n",
    "\n",
    "#add the cluster to the dataframe\n",
    "df['cluster'] = kmeans.fit_predict(X_train)\n",
    "df[\"test_cluster\"] = kmeans.fit_predict(X_test)\n",
    "# Compare matching scores for train and test sets\n",
    "train_clusters = df.groupby('cluster')['user_id'].apply(list).to_dict()\n",
    "test_clusters = df.groupby('test_cluster')['user_id'].apply(list).to_dict()\n",
    "\n",
    "# Calculate matching scores for train clusters\n",
    "train_matchings = []\n",
    "for cluster, customers in train_clusters.items():\n",
    "    for i in range(len(customers)):\n",
    "        for j in range(len(customers)):\n",
    "            if i != j:  # Avoid self-matching\n",
    "                train_matchings.append((customers[i], customers[j]))\n",
    "\n",
    "train_matches_df = pd.DataFrame(train_matchings, columns=['user_id', 'offer_id'])\n",
    "train_matches_df['matching_score'] = train_matches_df.apply(lambda row: calculate_matching_score(df_later, row['user_id'], row['offer_id']), axis=1)\n",
    "\n",
    "# Calculate matching scores for test clusters\n",
    "test_matchings = []\n",
    "for cluster, customers in test_clusters.items():\n",
    "    for i in range(len(customers)):\n",
    "        for j in range(len(customers)):\n",
    "            if i != j:  # Avoid self-matching\n",
    "                test_matchings.append((customers[i], customers[j]))\n",
    "\n",
    "test_matches_df = pd.DataFrame(test_matchings, columns=['user_id', 'offer_id'])\n",
    "test_matches_df['matching_score'] = test_matches_df.apply(lambda row: calculate_matching_score(df_later, row['user_id'], row['offer_id']), axis=1)\n",
    "\n",
    "# Print the matching scores for train and test sets\n",
    "print('Train matching scores:', train_matches_df['matching_score'].describe())\n",
    "print('Test matching scores:', test_matches_df['matching_score'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
