{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dynamically add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from db_config import db\n",
    "from db_config.db_tables import Matches, Offer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for matchings and matching scores\n",
    "matchings = []\n",
    "matchings_entries = []\n",
    "matching_score = 0\n",
    "\n",
    "#define matching score function\n",
    "# Calculate matching score based on euclidean distance\n",
    "def calculate_matching_score(df, user1, user2):\n",
    "    user1_preferences = df[df['user_id'] == user1].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    user2_preferences = df[df['user_id'] == user2].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    return euclidean(user1_preferences, user2_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define matching score function\n",
    "# Calculate matching score based on euclidean distance\n",
    "def calculate_matching_score(df, user1, user2):\n",
    "    user1_preferences = df[df['user_id'] == user1].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    user2_preferences = df[df['user_id'] == user2].drop(['user_id'], axis=1).apply(pd.to_numeric, errors='coerce').fillna(0).values.flatten()\n",
    "    return euclidean(user1_preferences, user2_preferences)\n",
    "\n",
    "#define clustering function\n",
    "def clustering_function(session_id):\n",
    "    df = pd.read_sql('SELECT * FROM preferences', db.engine)\n",
    "    df_later = df.copy()\n",
    "    \n",
    "    #replace NaNs with True to avoid errors\n",
    "    df = df.fillna(True)\n",
    "\n",
    "\n",
    "    #  Define features and hot-encode categorical variables\n",
    "    X = pd.get_dummies(df[[\"pets\", \"sex\", \"age\", \"smoking\"]])\n",
    "    #make sure true and false are replaced with 0 and 1\n",
    "    X = np.where(X == True, 1, X)\n",
    "    X = np.where(X == False, 0, X)\n",
    "    # Standardize features using MinMaxScaler (preprocessing to improve model performance)\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    #best cluster amount (as tested below)\n",
    "    best_cluster = 11\n",
    "\n",
    "    #fit the model for best amount of clusters\n",
    "    kmeans = KMeans(n_clusters=best_cluster)\n",
    "\n",
    "    #add the cluster to the dataframe\n",
    "    df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "    # Group customers by cluster\n",
    "    clusters = df.groupby('cluster')['user_id'].apply(list).to_dict()\n",
    "\n",
    "    # Add the matching customers to the matchings list\n",
    "    for cluster, customers in clusters.items():\n",
    "        for i in range(len(customers)):\n",
    "            for j in range(len(customers)):\n",
    "                if i != j:  # Avoid self-matching\n",
    "                    matchings.append((customers[i], customers[j]))\n",
    "\n",
    "    # Convert matches to a DataFrame for better clarity\n",
    "    matches_df = pd.DataFrame(matchings, columns=['user_id', 'offer_id'])\n",
    "\n",
    "    # Add matching score to matches_df\n",
    "    matches_df['matching_score'] = matches_df.apply(lambda row: calculate_matching_score(df_later, row['user_id'], row['offer_id']), axis=1)\n",
    "\n",
    "    # Sort matches by matching score in ascending order (lower distance means better match)\n",
    "    matches_df = matches_df.sort_values(by='matching_score')\n",
    "    # Normalize matching scores to a range of 0-100\n",
    "    min_score = matches_df['matching_score'].min()\n",
    "    max_score = matches_df['matching_score'].max()\n",
    "\n",
    "    matches_df['normalized_matching_score'] = 100 * (1 - (matches_df['matching_score'] - min_score) / (max_score - min_score))\n",
    "\n",
    "    # Print the DataFrame with normalized scores to check if it works\n",
    "    print(matches_df)\n",
    "    print(session_id)\n",
    "\n",
    "    # Add matches to the database \n",
    "    this_df = matches_df[matches_df['user_id'] == session_id]\n",
    "\n",
    "    print(this_df)\n",
    "\n",
    "    # delete old matches\n",
    "    Matches.query.filter_by(user_id=session_id).delete()\n",
    "    db.session.commit()\n",
    "    \n",
    "    for index, row in this_df.iterrows():\n",
    "        offer = Offer.query.filter_by(user_id=int(row['offer_id'])).first()\n",
    "        # append to database\n",
    "        new_match = Matches(\n",
    "            user_id=session_id,\n",
    "            offer_id=int(offer.id),\n",
    "            score=float(row['normalized_matching_score'])\n",
    "        )\n",
    "        db.session.add(new_match)\n",
    "    db.session.commit()\n",
    "\n",
    "    return matchings_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Silhouette Score is: 0.14285744272021533 for 38 clusters\n",
      "Best Test Silhouette Score is: 0.16161459525048968 for 11 clusters\n"
     ]
    }
   ],
   "source": [
    "#this cell compares the matching scores for train and test data to improve performance and avoid overfitting\n",
    "\n",
    "from app import app\n",
    "\n",
    "with app.app_context():\n",
    "    \n",
    "    df = pd.read_sql('SELECT * FROM preferences', db.engine)\n",
    "    df_later = df.copy()\n",
    "    #replace NaNs with True to avoid errors\n",
    "    df = df.fillna(True)\n",
    "\n",
    "    #  Define features and hot-encode categorical variables\n",
    "    X = pd.get_dummies(df[[\"smoking\", \"pets\", \"sex\", \"age\", \"relationship_status\", \"semester\", \"attendance\", \"community\", \"fitness\"]])\n",
    "\n",
    "    #make sure true and false are replaced with 0 and 1\n",
    "    X = np.where(X == True, 1, X)\n",
    "    X = np.where(X == False, 0, X)\n",
    "\n",
    "    # Split the data into training and testing sets (5 fold cross validation) to see how to model performs on unseen data\n",
    "    X_train, X_test, df_train, df_test = train_test_split(X, df, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Standardize features (preprocessing to improve model performance)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Ensure df_train and X_train have the same length\n",
    "    # Define our clusters\n",
    "    # Define cluster list, start from 10 so that silhouette score can be calculated\n",
    "    cluster_amount = list(range(10, 100))\n",
    "    best_score = -1\n",
    "    best_cluster = None\n",
    "    for i in cluster_amount:\n",
    "        kmeans = KMeans(n_clusters=i)\n",
    "        # Fit the model\n",
    "        df_train['cluster'] = kmeans.fit_predict(X_train)\n",
    "        \n",
    "        # Check if any cluster is too small\n",
    "        cluster_sizes = df_train['cluster'].value_counts()\n",
    "        min_cluster_size = 5  # Set your minimum cluster size here\n",
    "        if any(cluster_sizes < min_cluster_size):\n",
    "            continue  # Skip this iteration and try with a different number of clusters\n",
    "        # Evaluate performance using the silhouette score and find best performing cluster amount\n",
    "        silhouette_avg = silhouette_score(X_train, df_train['cluster'])\n",
    "        if silhouette_avg > best_score:\n",
    "            best_train_score = silhouette_avg\n",
    "            best_train_cluster = i\n",
    "        \n",
    "\n",
    "        # Evaluate performance on the test set\n",
    "        for i in cluster_amount:\n",
    "            kmeans = KMeans(n_clusters=i)\n",
    "            # Fit the model\n",
    "            df_test['cluster'] = kmeans.fit_predict(X_test)\n",
    "            # Check if any cluster is too small\n",
    "            cluster_sizes = df_test['cluster'].value_counts()\n",
    "            min_cluster_size = 5  # Set your minimum cluster size here\n",
    "            if any(cluster_sizes < min_cluster_size):\n",
    "                continue  # Skip this iteration and try with a different number of clusters\n",
    "            # Evaluate performance using the silhouette score and find best performing cluster amount\n",
    "            silhouette_avg = silhouette_score(X_test, df_test['cluster'])\n",
    "            if silhouette_avg > best_score:\n",
    "                best_test_score = silhouette_avg\n",
    "                best_test_cluster = i\n",
    "\n",
    "    print(f'Best Train Silhouette Score is: {best_train_score} for {best_train_cluster} clusters')\n",
    "    print(f'Best Test Silhouette Score is: {best_test_score} for {best_test_cluster} clusters')\n",
    "\n",
    "    #the best amount of clusters is 11 as this results in the lowest silhouette score for test data. this is the amount of clusters we \n",
    "    #use for our application \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
